import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import streamlit as st
from sklearn.preprocessing import MinMaxScaler, StandardScaler
from sklearn.metrics import mean_absolute_error, mean_squared_error, r2_score
import tensorflow as tf
from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import LSTM, Dense, Dropout, GRU, Conv1D, MaxPooling1D, Flatten
from tensorflow.keras.optimizers import Adam
from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau
import warnings
warnings.filterwarnings('ignore')
import sys
import os

# è®¾ç½®ä¸­æ–‡å­—ä½“
plt.rcParams['font.sans-serif'] = ['SimHei', 'Microsoft YaHei', 'DejaVu Sans']
plt.rcParams['axes.unicode_minus'] = False

# ç¡®ä¿æ­£ç¡®çš„åº”ç”¨åˆå§‹åŒ–
def main():
    # è®¾ç½®é¡µé¢é…ç½®ï¼ˆå¿…é¡»åœ¨å…¶ä»–streamlitè°ƒç”¨ä¹‹å‰ï¼‰
    st.set_page_config(
        page_title="æ¨¡å‹é€‰æ‹©åº”ç”¨",
        page_icon="ğŸ¤–",
        layout="wide",
        initial_sidebar_state="expanded"
    )

    # æ£€æŸ¥session_stateæ˜¯å¦æ­£ç¡®åˆå§‹åŒ–
    if 'initialized' not in st.session_state:
        st.session_state.initialized = True
        st.session_state.user_data = {}

    # ä¸»åº”ç”¨é€»è¾‘
    st.title("æ¨¡å‹é€‰æ‹©åº”ç”¨")
    st.write("åº”ç”¨æ­£åœ¨è¿è¡Œ...")

    # ä½ çš„å…¶ä»–ä»£ç ...


# æ·»åŠ é”™è¯¯å¤„ç†
if __name__ == "__main__":
    try:
        main()
    except Exception as e:
        st.error(f"åº”ç”¨å¯åŠ¨é”™è¯¯: {str(e)}")
        st.info("è¯·åˆ·æ–°é¡µé¢é‡è¯•")
# è®¾ç½®Matplotlibå­—ä½“ä»¥æ”¯æŒä¸­æ–‡æ˜¾ç¤º
# å¯¹äºæœ¬åœ°æµ‹è¯•ï¼Œè¯·ç¡®ä¿ç³»ç»Ÿå®‰è£…äº†SimHeiå­—ä½“ã€‚
# åœ¨æŸäº›äº‘ç¯å¢ƒä¸­ï¼Œå¯èƒ½éœ€è¦é¢å¤–é…ç½®å­—ä½“ï¼Œå¦åˆ™ä¼šå›é€€åˆ°é»˜è®¤å­—ä½“ã€‚
try:
    plt.rcParams['font.sans-serif'] = ['SimHei', 'DejaVu Sans']
    plt.rcParams['axes.unicode_minus'] = False
except Exception:
    st.warning("æ— æ³•ä¸ºMatplotlibè®¾ç½®ä¸­æ–‡å­—ä½“ã€‚å›¾è¡¨æ˜¾ç¤ºå¯èƒ½æ— æ³•æ­£ç¡®æ˜¾ç¤ºä¸­æ–‡å­—ç¬¦ã€‚")
    plt.rcParams['font.sans-serif'] = ['DejaVu Sans'] # å›é€€æ–¹æ¡ˆ
    plt.rcParams['axes.unicode_minus'] = False

# --- Streamlité¡µé¢é…ç½® ---
st.set_page_config(layout="wide", page_title="ç—…ä¾‹æ•°é¢„æµ‹åº”ç”¨")

st.title("ç—…ä¾‹æ•°æ—¶é—´åºåˆ—é¢„æµ‹")
st.markdown("ä½¿ç”¨æ·±åº¦å­¦ä¹ æ¨¡å‹ï¼ˆLSTM, GRU, CNN-LSTMï¼‰é¢„æµ‹ç—…ä¾‹æ•°ã€‚")


## æ•°æ®åŠ è½½ä¸åˆæ­¥å¤„ç†

@st.cache_data
def load_data():
    df = pd.read_csv('heal2.csv')
    df['ds'] = pd.to_datetime(df['ds'])
    df = df.sort_values('ds').reset_index(drop=True)
    return df

df = load_data()

st.subheader("æ•°æ®æ¦‚è§ˆ")
st.write(df.head())
st.write(f"æ•°æ®å½¢çŠ¶: {df.shape}")
st.write(f"æ—¶é—´èŒƒå›´: {df['ds'].min().strftime('%Y-%m-%d')} åˆ° {df['ds'].max().strftime('%Y-%m-%d')}")
st.write(f"ç—…ä¾‹æ•°èŒƒå›´: {df['y'].min()} åˆ° {df['y'].max()}")

# åŸå§‹æ•°æ®å¯è§†åŒ–ï¼ˆå¯é€‰åœ¨Streamlitä¸­æ˜¾ç¤ºï¼Œè¿™é‡Œä»…ç”¨äºå±•ç¤ºæ•°æ®ç‰¹æ€§ï¼‰
st.subheader("åŸå§‹æ•°æ®å¯è§†åŒ–")
fig_data, axes_data = plt.subplots(2, 2, figsize=(15, 10))

axes_data[0, 0].plot(df['ds'], df['y'], linewidth=2, color='red')
axes_data[0, 0].set_title('ç—…ä¾‹æ•°æ—¶é—´åºåˆ—', fontsize=14, fontweight='bold')
axes_data[0, 0].set_xlabel('æ—¥æœŸ')
axes_data[0, 0].set_ylabel('ç—…ä¾‹æ•°')
axes_data[0, 0].grid(True, alpha=0.3)

axes_data[0, 1].scatter(df['temperature'], df['y'], alpha=0.6, color='orange')
axes_data[0, 1].set_title('æ¸©åº¦ vs ç—…ä¾‹æ•°', fontsize=14, fontweight='bold')
axes_data[0, 1].set_xlabel('æ¸©åº¦ (Â°C)')
axes_data[0, 1].set_ylabel('ç—…ä¾‹æ•°')
axes_data[0, 1].grid(True, alpha=0.3)

axes_data[1, 0].scatter(df['humidity'], df['y'], alpha=0.6, color='blue')
axes_data[1, 0].set_title('æ¹¿åº¦ vs ç—…ä¾‹æ•°', fontsize=14, fontweight='bold')
axes_data[1, 0].set_xlabel('æ¹¿åº¦')
axes_data[1, 0].set_ylabel('ç—…ä¾‹æ•°')
axes_data[1, 0].grid(True, alpha=0.3)

weekend_cases = df.groupby('is_weekend')['y'].mean()
axes_data[1, 1].bar(['å·¥ä½œæ—¥', 'å‘¨æœ«'], weekend_cases.values, color=['lightblue', 'lightcoral'])
axes_data[1, 1].set_title('å·¥ä½œæ—¥ vs å‘¨æœ«å¹³å‡ç—…ä¾‹æ•°', fontsize=14, fontweight='bold')
axes_data[1, 1].set_ylabel('å¹³å‡ç—…ä¾‹æ•°')
axes_data[1, 1].grid(True, alpha=0.3)

plt.tight_layout()
st.pyplot(fig_data)




## ç‰¹å¾å·¥ç¨‹å‡½æ•°


def create_features(df_input):
    df_copy = df_input.copy()

    # æ—¶é—´ç‰¹å¾
    df_copy['day_of_year'] = df_copy['ds'].dt.dayofyear
    df_copy['month'] = df_copy['ds'].dt.month
    df_copy['day_of_week'] = df_copy['ds'].dt.dayofweek
    df_copy['week_of_year'] = df_copy['ds'].dt.isocalendar().week.astype(int) # ç¡®ä¿ä¸ºæ•´æ•°ç±»å‹

    # å‘¨æœŸæ€§ç‰¹å¾
    df_copy['sin_day'] = np.sin(2 * np.pi * df_copy['day_of_year'] / 365.25)
    df_copy['cos_day'] = np.cos(2 * np.pi * df_copy['day_of_year'] / 365.25)
    df_copy['sin_week'] = np.sin(2 * np.pi * df_copy['day_of_week'] / 7)
    df_copy['cos_week'] = np.cos(2 * np.pi * df_copy['day_of_week'] / 7)

    # æ»åç‰¹å¾
    for lag in [1, 3, 7, 14]:
        df_copy[f'y_lag_{lag}'] = df_copy['y'].shift(lag)

    # ç§»åŠ¨å¹³å‡ç‰¹å¾
    for window in [3, 7, 14]:
        df_copy[f'y_ma_{window}'] = df_copy['y'].rolling(window=window).mean()
        df_copy[f'temp_ma_{window}'] = df_copy['temperature'].rolling(window=window).mean()

    # å¡«å……NaNå€¼ (bfillåffillç¡®ä¿åŒå‘å¡«å……)
    df_copy = df_copy.fillna(method='bfill').fillna(method='ffill')

    return df_copy

df_features = create_features(df.copy()) # ä½¿ç”¨ df çš„å‰¯æœ¬è¿›è¡Œç‰¹å¾å·¥ç¨‹

# å®šä¹‰ç‰¹å¾åˆ—
feature_cols = ['temperature', 'humidity', 'is_weekend', 'school_holiday',
                'day_of_year', 'month', 'day_of_week', 'week_of_year',
                'sin_day', 'cos_day', 'sin_week', 'cos_week',
                'y_lag_1', 'y_lag_3', 'y_lag_7', 'y_lag_14',
                'y_ma_3', 'y_ma_7', 'y_ma_14', 'temp_ma_3', 'temp_ma_7', 'temp_ma_14']


def create_sequences(data, target, feature_cols, seq_length):
    X, y = [], []
    for i in range(seq_length, len(data)):
        X.append(data[feature_cols].iloc[i-seq_length:i].values)
        y.append(target.iloc[i])
    return np.array(X), np.array(y)
def build_lstm_model(input_shape, learning_rate, dropout):
    model = Sequential([
        LSTM(128, return_sequences=True, input_shape=input_shape),
        Dropout(dropout),
        LSTM(64, return_sequences=True),
        Dropout(dropout),
        LSTM(32, return_sequences=False),
        Dropout(dropout),
        Dense(16, activation='relu'),
        Dense(1, activation='linear')
    ])
    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='huber', metrics=['mae'])
    return model

def build_gru_model(input_shape, learning_rate, dropout):
    model = Sequential([
        GRU(128, return_sequences=True, input_shape=input_shape),
        Dropout(dropout),
        GRU(64, return_sequences=False),
        Dropout(dropout),
        Dense(32, activation='relu'),
        Dense(16, activation='relu'),
        Dense(1, activation='linear')
    ])
    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='huber', metrics=['mae'])
    return model

def build_cnn_lstm_model(input_shape, learning_rate, dropout):
    model = Sequential([
        Conv1D(filters=64, kernel_size=3, activation='relu', input_shape=input_shape),
        MaxPooling1D(pool_size=2),
        LSTM(50, return_sequences=True),
        Dropout(dropout),
        LSTM(25, return_sequences=False),
        Dropout(dropout),
        Dense(16, activation='relu'),
        Dense(1, activation='linear')
    ])
    model.compile(optimizer=Adam(learning_rate=learning_rate), loss='huber', metrics=['mae'])
    return model
st.sidebar.header("æ¨¡å‹é…ç½®")

selected_model_name = st.sidebar.selectbox(
    "é€‰æ‹©æ¨¡å‹:",
    ('LSTM', 'GRU', 'CNN-LSTM')
)

st.sidebar.subheader("æ¨¡å‹è¶…å‚æ•°")
seq_length = st.sidebar.slider("åºåˆ—é•¿åº¦ (å¤©):", 7, 30, 14)
epochs = st.sidebar.slider("è®­ç»ƒè½®æ¬¡ (Epochs):", 10, 200, 100)
batch_size = st.sidebar.slider("æ‰¹æ¬¡å¤§å° (Batch Size):", 16, 128, 32)
learning_rate = st.sidebar.slider("å­¦ä¹ ç‡ (Learning Rate):", 0.0001, 0.01, 0.001, format="%.4f")
dropout_rate = st.sidebar.slider("Dropout æ¯”ç‡:", 0.0, 0.5, 0.2, format="%.2f")

st.sidebar.subheader("å›è°ƒå‡½æ•°å‚æ•°")
es_patience = st.sidebar.slider("æ—©åœè€å¿ƒ (Early Stopping Patience):", 5, 50, 20)
rlr_patience = st.sidebar.slider("å­¦ä¹ ç‡ä¸‹é™è€å¿ƒ (RLRPatience):", 5, 30, 10)
rlr_factor = st.sidebar.slider("å­¦ä¹ ç‡ä¸‹é™å› å­ (RLRFactor):", 0.1, 0.9, 0.5, format="%.1f")

train_button = st.sidebar.button("è®­ç»ƒå¹¶è¯„ä¼°æ¨¡å‹")
if train_button:
    st.subheader(f"æ­£åœ¨è®­ç»ƒå’Œè¯„ä¼° {selected_model_name} æ¨¡å‹...")
    st.markdown("è¯·è€å¿ƒç­‰å¾…ï¼Œè®­ç»ƒå¯èƒ½éœ€è¦ä¸€äº›æ—¶é—´ã€‚")

    with st.spinner('æ•°æ®å‡†å¤‡ä¸­...'):
        # æ•°æ®æ ‡å‡†åŒ– (ç”±äºseq_lengthå¯èƒ½æ”¹å˜æ•°æ®å½¢çŠ¶ï¼Œéœ€è¦é‡æ–°fit)
        scaler_X = StandardScaler()
        scaler_y = MinMaxScaler()

        X_scaled = scaler_X.fit_transform(df_features[feature_cols])
        y_scaled = scaler_y.fit_transform(df_features[['y']])

        df_scaled = pd.DataFrame(X_scaled, columns=feature_cols)
        df_scaled['y'] = y_scaled

        # æ ¹æ®é€‰æ‹©çš„åºåˆ—é•¿åº¦åˆ›å»ºåºåˆ—æ•°æ®
        X_seq, y_seq = create_sequences(df_scaled, df_scaled['y'], feature_cols, seq_length)

        # è®­ç»ƒé›†å’Œæµ‹è¯•é›†åˆ†å‰²
        train_size = int(0.8 * len(X_seq))
        X_train, X_test = X_seq[:train_size], X_seq[train_size:]
        y_train, y_test = y_seq[:train_size], y_seq[train_size:]

        st.success("æ•°æ®å‡†å¤‡å®Œæˆï¼")
        st.write(f"è®­ç»ƒé›†å½¢çŠ¶: X_train: {X_train.shape}, y_train: {y_train.shape}")
        st.write(f"æµ‹è¯•é›†å½¢çŠ¶: X_test: {X_test.shape}, y_test: {y_test.shape}")

    with st.spinner(f'æ­£åœ¨è®­ç»ƒ {selected_model_name} æ¨¡å‹...'):
        # æ„å»ºé€‰å®šçš„æ¨¡å‹
        input_shape = (X_train.shape[1], X_train.shape[2])
        if selected_model_name == 'LSTM':
            model = build_lstm_model(input_shape, learning_rate, dropout_rate)
        elif selected_model_name == 'GRU':
            model = build_gru_model(input_shape, learning_rate, dropout_rate)
        else: # CNN-LSTM
            model = build_cnn_lstm_model(input_shape, learning_rate, dropout_rate)

        # å›è°ƒå‡½æ•°
        callbacks = [
            EarlyStopping(monitor='val_loss', patience=es_patience, restore_best_weights=True, verbose=0),
            ReduceLROnPlateau(monitor='val_loss', factor=rlr_factor, patience=rlr_patience, min_lr=0.0001, verbose=0)
        ]

        history = model.fit(
            X_train, y_train,
            epochs=epochs,
            batch_size=batch_size,
            validation_split=0.2,
            callbacks=callbacks,
            verbose=0 # æŠ‘åˆ¶æ§åˆ¶å°çš„è¯¦ç»†è¾“å‡ºï¼ŒStreamlitä¼šå¤„ç†è¿›åº¦
        )
        st.success(f"{selected_model_name} æ¨¡å‹è®­ç»ƒå®Œæˆï¼")

    with st.spinner('æ­£åœ¨è¯„ä¼°æ¨¡å‹å¹¶è¿›è¡Œé¢„æµ‹...'):
        # é¢„æµ‹
        train_pred = model.predict(X_train, verbose=0)
        test_pred = model.predict(X_test, verbose=0)

        # åæ ‡å‡†åŒ–ï¼Œå¹¶è½¬æ¢ä¸ºæ•´æ•°
        train_pred_orig = np.maximum(0, np.round(scaler_y.inverse_transform(train_pred.reshape(-1, 1)))).astype(int).flatten()
        test_pred_orig = np.maximum(0, np.round(scaler_y.inverse_transform(test_pred.reshape(-1, 1)))).astype(int).flatten()
        y_train_orig = scaler_y.inverse_transform(y_train.reshape(-1, 1)).flatten()
        y_test_orig = scaler_y.inverse_transform(y_test.reshape(-1, 1)).flatten()

        # è®¡ç®—è¯„ä¼°æŒ‡æ ‡
        train_mae = mean_absolute_error(y_train_orig, train_pred_orig)
        test_mae = mean_absolute_error(y_test_orig, test_pred_orig)
        train_rmse = np.sqrt(mean_squared_error(y_train_orig, train_pred_orig))
        test_rmse = np.sqrt(mean_squared_error(y_test_orig, test_pred_orig))
        train_r2 = r2_score(y_train_orig, train_pred_orig)
        test_r2 = r2_score(y_test_orig, test_pred_orig)

        st.subheader(f"{selected_model_name} æ¨¡å‹è¯„ä¼°ç»“æœ")
        col1, col2, col3 = st.columns(3)
        with col1:
            st.metric("è®­ç»ƒé›† MAE", f"{train_mae:.2f}")
            st.metric("æµ‹è¯•é›† MAE", f"{test_mae:.2f}")
        with col2:
            st.metric("è®­ç»ƒé›† RMSE", f"{train_rmse:.2f}")
            st.metric("æµ‹è¯•é›† RMSE", f"{test_rmse:.2f}")
        with col3:
            st.metric("è®­ç»ƒé›† RÂ²", f"{train_r2:.3f}")
            st.metric("æµ‹è¯•é›† RÂ²", f"{test_r2:.3f}")

        st.subheader("è®­ç»ƒæŸå¤±å†å²")
        fig_loss, ax_loss = plt.subplots(figsize=(10, 6))
        ax_loss.plot(history.history['loss'], label='è®­ç»ƒé›† Loss')
        ax_loss.plot(history.history['val_loss'], label='éªŒè¯é›† Loss', linestyle='--')
        ax_loss.set_title(f'{selected_model_name} æ¨¡å‹è®­ç»ƒæŸå¤±', fontsize=14, fontweight='bold')
        ax_loss.set_xlabel('Epoch')
        ax_loss.set_ylabel('Loss')
        ax_loss.legend()
        ax_loss.grid(True, alpha=0.3)
        st.pyplot(fig_loss)

        st.subheader(f"{selected_model_name} æ¨¡å‹é¢„æµ‹ç»“æœ")
        fig_pred, ax_pred = plt.subplots(figsize=(15, 8))

        # å‡†å¤‡ç»˜å›¾æ•°æ®
        train_dates = df['ds'].iloc[seq_length:seq_length+len(train_pred_orig)]
        test_dates = df['ds'].iloc[seq_length+len(train_pred_orig):]
        train_actual = df['y'].iloc[seq_length:seq_length+len(train_pred_orig)]
        test_actual = df['y'].iloc[seq_length+len(train_pred_orig):]

        ax_pred.plot(train_dates, train_actual, 'b-', label='è®­ç»ƒé›†å®é™…', linewidth=2)
        ax_pred.plot(test_dates, test_actual, 'g-', label='æµ‹è¯•é›†å®é™…', linewidth=2)
        ax_pred.plot(train_dates, train_pred_orig, 'r--', label='è®­ç»ƒé›†é¢„æµ‹', alpha=0.8)
        ax_pred.plot(test_dates, test_pred_orig, 'orange', linestyle='--', label='æµ‹è¯•é›†é¢„æµ‹', alpha=0.8)

        ax_pred.set_title(f'{selected_model_name} æ¨¡å‹å®é™…ä¸é¢„æµ‹', fontsize=14, fontweight='bold')
        ax_pred.set_xlabel('æ—¥æœŸ')
        ax_pred.set_ylabel('ç—…ä¾‹æ•°')
        ax_pred.legend(fontsize=10)
        ax_pred.grid(True, alpha=0.3)
        plt.xticks(rotation=45)
        st.pyplot(fig_pred)

        st.subheader("æœªæ¥28å¤©é¢„æµ‹")

        # --- æœªæ¥28å¤©é¢„æµ‹é€»è¾‘ ---
        # å‡†å¤‡ç”¨äºé¢„æµ‹çš„æœ€åä¸€ä¸ªåºåˆ—
        last_sequence_data = df_scaled[feature_cols].iloc[-seq_length:].values
        last_sequence = last_sequence_data.reshape(1, seq_length, len(feature_cols))

        future_predictions = []
        last_date = df['ds'].iloc[-1]
        future_dates = pd.date_range(start=last_date + pd.Timedelta(days=1), periods=28, freq='D')

        # åˆ›å»ºä¸€ä¸ªDataFrameæ¥å­˜å‚¨æœªæ¥ç‰¹å¾ï¼Œæ–¹ä¾¿æŒ‰åˆ—åè®¿é—®
        future_features_df = pd.DataFrame(index=future_dates, columns=feature_cols)

        # å¡«å……é™æ€çš„æœªæ¥ç‰¹å¾ï¼ˆæ¸©åº¦/æ¹¿åº¦ä¼°ç®—ã€æ—¶é—´ç‰¹å¾ã€å‘¨æœ«/èŠ‚å‡æ—¥ï¼‰
        for date in future_dates:
            day_of_year = date.dayofyear
            # ç®€åŒ–çš„æœªæ¥æ¸©åº¦/æ¹¿åº¦ä¼°ç®—ï¼ˆå¯æ ¹æ®å®é™…æƒ…å†µæ›¿æ¢ä¸ºæ›´ç²¾ç¡®çš„é¢„æµ‹ï¼‰
            temp_estimate = 15 + 10 * np.sin(2 * np.pi * (day_of_year - 80) / 365.25)
            humidity_estimate = 0.65
            is_weekend = 1 if date.weekday() >= 5 else 0
            school_holiday = 0 # å‡è®¾æœªæ¥éå‡æœŸ

            future_features_df.loc[date, ['temperature', 'humidity', 'is_weekend', 'school_holiday']] = \
                [temp_estimate, humidity_estimate, is_weekend, school_holiday]

            future_features_df.loc[date, 'day_of_year'] = day_of_year
            future_features_df.loc[date, 'month'] = date.month
            future_features_df.loc[date, 'day_of_week'] = date.weekday()
            future_features_df.loc[date, 'week_of_year'] = date.isocalendar().week
            future_features_df.loc[date, 'sin_day'] = np.sin(2 * np.pi * day_of_year / 365.25)
            future_features_df.loc[date, 'cos_day'] = np.cos(2 * np.pi * day_of_year / 365.25)
            future_features_df.loc[date, 'sin_week'] = np.sin(2 * np.pi * date.weekday() / 7)
            future_features_df.loc[date, 'cos_week'] = np.cos(2 * np.pi * date.weekday() / 7)

        # è¿­ä»£é¢„æµ‹å¹¶æ›´æ–°æ»å/ç§»åŠ¨å¹³å‡ç‰¹å¾
        temp_historical_y = df['y'].tolist() # ä¿ç•™å†å²yå€¼
        temp_future_y_predictions = [] # å­˜å‚¨é¢„æµ‹çš„yå€¼ï¼Œç”¨äºè®¡ç®—æœªæ¥çš„æ»åå’Œç§»åŠ¨å¹³å‡

        for i in range(28):
            current_date_features = future_features_df.iloc[i].copy()

            # æ›´æ–°æ»åç‰¹å¾ï¼šä¼˜å…ˆä½¿ç”¨å·²é¢„æµ‹çš„æœªæ¥å€¼ï¼Œä¸è¶³åˆ™ä½¿ç”¨å†å²å€¼
            current_date_features['y_lag_1'] = temp_future_y_predictions[-1] if i >= 1 else temp_historical_y[-1]
            current_date_features['y_lag_3'] = temp_future_y_predictions[-3] if i >= 3 else temp_historical_y[max(0, len(temp_historical_y)-3)]
            current_date_features['y_lag_7'] = temp_future_y_predictions[-7] if i >= 7 else temp_historical_y[max(0, len(temp_historical_y)-7)]
            current_date_features['y_lag_14'] = temp_future_y_predictions[-14] if i >= 14 else temp_historical_y[max(0, len(temp_historical_y)-14)]

            # æ›´æ–°ç§»åŠ¨å¹³å‡ç‰¹å¾ï¼šç»“åˆå†å²å’Œå·²é¢„æµ‹çš„æœªæ¥å€¼è®¡ç®—
            combined_y_for_ma = temp_historical_y + temp_future_y_predictions
            current_date_features['y_ma_3'] = np.mean(combined_y_for_ma[-3:]) if len(combined_y_for_ma) >= 3 else combined_y_for_ma[-1]
            current_date_features['y_ma_7'] = np.mean(combined_y_for_ma[-7:]) if len(combined_y_for_ma) >= 7 else combined_y_for_ma[-1]
            current_date_features['y_ma_14'] = np.mean(combined_y_for_ma[-14:]) if len(combined_y_for_ma) >= 14 else combined_y_for_ma[-1]

            # ç®€åŒ–çš„æ¸©åº¦ç§»åŠ¨å¹³å‡ï¼ˆè‹¥æœ‰æ¸©åº¦é¢„æµ‹å¯æ›´å¤æ‚ï¼‰
            current_date_features['temp_ma_3'] = current_date_features['temperature']
            current_date_features['temp_ma_7'] = current_date_features['temperature']
            current_date_features['temp_ma_14'] = current_date_features['temperature']

            # å¯¹å½“å‰ç‰¹å¾è¿›è¡Œæ ‡å‡†åŒ–
            new_features_array = np.array([current_date_features[col] for col in feature_cols]).reshape(1, -1)
            new_features_scaled = scaler_X.transform(new_features_array)

            # æ›´æ–° last_sequence ç”¨äºä¸‹ä¸€æ¬¡é¢„æµ‹ï¼šå·¦ç§»ä¸€ä¸ªæ—¶é—´æ­¥ï¼Œå¹¶åŠ å…¥æ–°çš„ç‰¹å¾
            last_sequence = np.roll(last_sequence, -1, axis=1)
            last_sequence[0, -1, :] = new_features_scaled[0]

            # é¢„æµ‹ä¸‹ä¸€ä¸ªå€¼
            pred_scaled = model.predict(last_sequence, verbose=0)[0, 0]
            pred_orig = scaler_y.inverse_transform([[pred_scaled]])[0, 0]

            # è½¬æ¢ä¸ºæ•´æ•°å¹¶ç¡®ä¿éè´Ÿ
            rounded_pred = np.maximum(0, np.round(pred_orig)).astype(int)

            future_predictions.append(rounded_pred)
            temp_future_y_predictions.append(rounded_pred) # å°†å››èˆäº”å…¥åçš„æ•´æ•°å€¼åŠ å…¥åˆ—è¡¨

        future_df = pd.DataFrame({
            'æ—¥æœŸ': future_dates,
            'é¢„æµ‹ç—…ä¾‹æ•°': future_predictions # æ­¤åˆ—è¡¨ç°åœ¨åŒ…å«æ•´æ•°
        })

        st.dataframe(future_df)

        # å¯è§†åŒ–æœªæ¥é¢„æµ‹
        fig_future, ax_future = plt.subplots(figsize=(15, 8))
        ax_future.plot(df['ds'], df['y'], 'b-', label='å†å²ç—…ä¾‹æ•°', linewidth=2)
        ax_future.plot(future_dates, future_predictions, 'r-', label='æœªæ¥28å¤©é¢„æµ‹', linewidth=2, marker='o')

        # æ·»åŠ é¢„æµ‹åŒºé—´ï¼ˆä½¿ç”¨ç®€åŒ–çš„ç½®ä¿¡åŒºé—´ï¼ŒåŸºäºè¿‘æœŸå†å²çš„æ ‡å‡†å·®ï¼‰
        pred_std_hist = np.std(df['y'].tail(seq_length)) # ä½¿ç”¨è¿‘æœŸå®é™…å€¼çš„æ ‡å‡†å·®
        lower_bound = np.array(future_predictions) - 1.96 * pred_std_hist
        upper_bound = np.array(future_predictions) + 1.96 * pred_std_hist
        # ç¡®ä¿ç½®ä¿¡åŒºé—´ä¸‹é™ä¸ä¸ºè´Ÿ
        ax_future.fill_between(future_dates, np.maximum(0, lower_bound), upper_bound,
                                alpha=0.3, color='red', label='95% ç½®ä¿¡åŒºé—´')

        ax_future.axvline(x=df['ds'].iloc[-1], color='green', linestyle='--', alpha=0.7, label='é¢„æµ‹èµ·å§‹ç‚¹')
        ax_future.set_title('ç—…ä¾‹æ•°é¢„æµ‹ - æœªæ¥28å¤©', fontsize=16, fontweight='bold')
        ax_future.set_xlabel('æ—¥æœŸ')
        ax_future.set_ylabel('ç—…ä¾‹æ•°')
        ax_future.legend()
        ax_future.grid(True, alpha=0.3)
        plt.xticks(rotation=45)
        st.pyplot(fig_future)

        st.subheader("é¢„æµ‹è¶‹åŠ¿åˆ†æ")
        avg_prediction = np.mean(future_predictions)
        if avg_prediction > df['y'].tail(7).mean():
            st.markdown("âš ï¸ **é¢„æµ‹æ˜¾ç¤ºæœªæ¥ç—…ä¾‹æ•°å‘ˆä¸Šå‡è¶‹åŠ¿**")
        else:
            st.markdown("âœ… **é¢„æµ‹æ˜¾ç¤ºæœªæ¥ç—…ä¾‹æ•°ç›¸å¯¹ç¨³å®šæˆ–ä¸‹é™**")

        st.write(f"æœªæ¥28å¤©å¹³å‡é¢„æµ‹ç—…ä¾‹æ•°: {avg_prediction:.1f}")
        st.write(f"é¢„æµ‹å³°å€¼: {max(future_predictions):.0f} (åœ¨æœªæ¥ç¬¬ {future_predictions.index(max(future_predictions))+1} å¤©)")
        st.write(f"é¢„æµ‹æœ€ä½å€¼: {min(future_predictions):.0f} (åœ¨æœªæ¥ç¬¬ {future_predictions.index(min(future_predictions))+1} å¤©)")